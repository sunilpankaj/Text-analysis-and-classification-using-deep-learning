{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentimental analysis using deep learning.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDfqAalBj2mA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wi081Ezn1XQ",
        "colab_type": "code",
        "outputId": "3621586b-6dc8-458a-d75c-a068389f561c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.0-rc2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6n33Rg4n2yr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Dense, Input, Flatten, Dropout,concatenate\n",
        "from tensorflow.keras.layers import Conv1D,Conv2D, MaxPooling1D, Embedding\n",
        "from tensorflow.keras.layers import LSTM, Bidirectional, GRU\n",
        "from tensorflow.keras.models import Model,Sequential\n",
        "from tensorflow.keras.callbacks import EarlyStopping,LearningRateScheduler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5m1MflapL4d",
        "colab_type": "code",
        "outputId": "94eec96d-64aa-47d2-d578-73afb5d68546",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "#using google colab mounting drive to colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPNjwaQkvEXa",
        "colab_type": "code",
        "outputId": "f0bff9fb-9dbf-4f51-ab9c-b8a6890141bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "source": [
        "tweet = pd.read_csv(\"/content/drive/My Drive/google_colab/Tweets.csv\")\n",
        "tweet.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>airline_sentiment_confidence</th>\n",
              "      <th>negativereason</th>\n",
              "      <th>negativereason_confidence</th>\n",
              "      <th>airline</th>\n",
              "      <th>airline_sentiment_gold</th>\n",
              "      <th>name</th>\n",
              "      <th>negativereason_gold</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>text</th>\n",
              "      <th>tweet_coord</th>\n",
              "      <th>tweet_created</th>\n",
              "      <th>tweet_location</th>\n",
              "      <th>user_timezone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>570306133677760513</td>\n",
              "      <td>neutral</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>cairdin</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica What @dhepburn said.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:35:52 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Eastern Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>570301130888122368</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.3486</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:59 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>570301083672813571</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.6837</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>yvonnalynn</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:48 -0800</td>\n",
              "      <td>Lets Play</td>\n",
              "      <td>Central Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>570301031407624196</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Bad Flight</td>\n",
              "      <td>0.7033</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:36 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>570300817074462722</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Can't Tell</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:14:45 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             tweet_id  ...               user_timezone\n",
              "0  570306133677760513  ...  Eastern Time (US & Canada)\n",
              "1  570301130888122368  ...  Pacific Time (US & Canada)\n",
              "2  570301083672813571  ...  Central Time (US & Canada)\n",
              "3  570301031407624196  ...  Pacific Time (US & Canada)\n",
              "4  570300817074462722  ...  Pacific Time (US & Canada)\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vAABsq0vtrm",
        "colab_type": "code",
        "outputId": "105d85ae-9a57-491f-ec66-8f44f66da142",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from nltk.tokenize import RegexpTokenizer\n",
        "def standardize_text(df, text_field):\n",
        "    df[text_field] = df[text_field].str.replace(r\"http\\S+\", \"\")\n",
        "    df[text_field] = df[text_field].str.replace(r\"http\", \"\")\n",
        "    df[text_field] = df[text_field].str.replace(r\"@\\S+\", \"\")\n",
        "    df[text_field] = df[text_field].str.replace(r\"[^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]\", \" \")\n",
        "    df[text_field] = df[text_field].str.replace(r\"@\", \"at\")\n",
        "    df[text_field] = df[text_field].str.lower()\n",
        "    return df\n",
        "    \n",
        "data = tweet[['text', 'airline_sentiment']]\n",
        "tweet_text = standardize_text(data, \"text\")\n",
        "\n",
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "tweet_text[\"tokens\"] = tweet_text[\"text\"].apply(tokenizer.tokenize)\n",
        "#transforming postive to 2, netural to 1, negative to 0\n",
        "sentiment = sorted(tweet_text['airline_sentiment'].unique())\n",
        "print (sentiment)\n",
        "sentiment_mapping = dict(zip(sentiment, range(0, len(sentiment) + 1)))\n",
        "tweet_text['airline_sentiment']  = tweet_text['airline_sentiment'].map(sentiment_mapping).astype(int)\n",
        "\n",
        "all_words = [word for tokens in tweet_text[\"tokens\"] for word in tokens]\n",
        "sentence_lengths = [len(tokens) for tokens in tweet_text[\"tokens\"]]\n",
        "VOCAB = sorted(list(set(all_words)))\n",
        "print(\"%s words total, with a vocabulary size of %s\" % (len(all_words), len(VOCAB)))\n",
        "print(\"Max & min sentence length is %s & %s\" %(max(sentence_lengths), min(sentence_lengths)))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['negative', 'neutral', 'positive']\n",
            "247352 words total, with a vocabulary size of 13088\n",
            "Max & min sentence length is 34 & 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkaTtF5Px7HB",
        "colab_type": "code",
        "outputId": "bf971d1a-1607-4729-d6a8-9710061a5f43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tweet.shape, data.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((14640, 15), (14640, 3))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2--yxRkwN_B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gensim\n",
        "word2vec_path = \"/content/drive/My Drive/google_colab/GoogleNews-vectors-negative300.bin.gz\"\n",
        "word2vec = gensim.models.KeyedVectors.load_word2vec_format(word2vec_path, binary=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGaEPCVnxcJw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_average_word2vec(tokens_list, vector, generate_missing=False, k=300):\n",
        "  if len(tokens_list)<1:\n",
        "    return np.zeros(k)\n",
        "  if generate_missing:\n",
        "    vectorized = [vector[word] if word in vector else np.random.rand(k) for word in tokens_list]\n",
        "  else:\n",
        "    vectorized = [vector[word] if word in vector else np.zeros(k) for word in tokens_list]\n",
        "  length = len(vectorized)\n",
        "  summed = np.sum(vectorized, axis=0)\n",
        "  averaged = np.divide(summed, length)\n",
        "  return averaged\n",
        "\n",
        "def get_word2vec_embeddings(vectors, data, generate_missing=False):\n",
        "  embeddings = data['tokens'].apply(lambda x: get_average_word2vec(x, vectors,generate_missing=generate_missing))\n",
        "  return list(embeddings)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmkv_VtSyPZq",
        "colab_type": "code",
        "outputId": "1701be93-02ee-4df8-bb94-2d0ebba7657f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "embeddings = get_word2vec_embeddings(word2vec, data)\n",
        "len(embeddings)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14640"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eIr-KrEySvM",
        "colab_type": "code",
        "outputId": "33adef24-3695-466e-f17d-54e57f8f9d25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "EMBEDDING_DIM = 300\n",
        "MAX_SEQUENCE_LENGTH = 34\n",
        "VOCAB_SIZE = len(VOCAB)\n",
        "VALIDATION_SPLIT=.3\n",
        "tokenizer = Tokenizer(num_words=VOCAB_SIZE)\n",
        "tokenizer.fit_on_texts(data[\"text\"].tolist()) #tokenize\n",
        "sequences = tokenizer.texts_to_sequences(data[\"text\"].tolist()) #list of each sentence as number index \n",
        "word_index = tokenizer.word_index  #index of tokenized  word\n",
        "print('Found %s unique tokens.' % len(word_index))\n",
        "\n",
        "cnn_data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH) #dding padding to front , converiting all sentece length to 34 \n",
        "labels = to_categorical(np.asarray(tweet_text['airline_sentiment']))\n",
        "#randomly suffle data\n",
        "indices = np.arange(cnn_data.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "cnn_data = cnn_data[indices]\n",
        "labels = labels[indices]\n",
        "\n",
        "embedding_weights = np.zeros((len(word_index)+1, EMBEDDING_DIM))\n",
        "#extracting each word embedding of 300 size\n",
        "for word,index in word_index.items():\n",
        "    embedding_weights[index,:] = word2vec[word] if word in word2vec else np.random.rand(EMBEDDING_DIM)\n",
        "print(embedding_weights.shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 13346 unique tokens.\n",
            "(13347, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmny_AWN08EW",
        "colab_type": "code",
        "outputId": "5ed64158-a14b-4582-bac7-d95e478219b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "num_words = len(word_index)+1\n",
        "# embedding_layer = Embedding(num_words,\n",
        "#                             EMBEDDING_DIM,\n",
        "#                             weights=[embedding_weights],\n",
        "#                             input_length=MAX_SEQUENCE_LENGTH,\n",
        "#                             trainable=False)\n",
        "\n",
        "#input to the model will be embedding of sentence as follow \n",
        "#sentence is : \"flight is good\" \n",
        "#this sentence will convert into size of 34 workds with padding\n",
        "#now each word will have embedding of 300\n",
        "#so input matrix will be 34x300\n",
        "train_sample = int(0.7 * cnn_data.shape[0])\n",
        "val_samples = int(0.15 * cnn_data.shape[0])\n",
        "test_samples = int(0.15 * cnn_data.shape[0])\n",
        "\n",
        "x_train = cnn_data[:train_sample]\n",
        "y_train = labels[:train_sample]\n",
        "x_val = cnn_data[train_sample:train_sample+val_samples]\n",
        "y_val = labels[train_sample:train_sample+val_samples]\n",
        "x_test = cnn_data[-test_samples:]\n",
        "y_test = labels[-test_samples:]\n",
        "print (x_train.shape, x_val.shape, x_test.shape, y_val.shape,y_train.shape)\n",
        "#print (x_train[-5:], x_val[-5:], x_test[-5:])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10248, 34) (2196, 34) (2196, 34) (2196, 3) (10248, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrWClGseyVNh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def LSTM_model(num_words,EMBEDDING_DIM,embedding_weights,max_sequence_length,labels_index):\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(num_words, EMBEDDING_DIM, weights=[embedding_weights],\n",
        "                      input_length=max_sequence_length,\n",
        "                     trainable=False))\n",
        "  model.add(LSTM(100,dropout=0.2))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(labels_index, activation='sigmoid'))\n",
        "  print(model.summary())\n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "                optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-3),\n",
        "                metrics=['acc'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eMrDoiI4xQw",
        "colab_type": "code",
        "outputId": "257730a9-517d-4592-e485-622f4eb77243",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        }
      },
      "source": [
        "model = LSTM_model(num_words, EMBEDDING_DIM,embedding_weights,MAX_SEQUENCE_LENGTH,len(list(tweet_text['airline_sentiment'].unique())))\n",
        "#model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=50, batch_size=128)\n",
        "callback = EarlyStopping(monitor='val_loss', patience=5,restore_best_weights=True,mode=\"min\")\n",
        "# This callback will stop the training when there is no improvement in\n",
        "# the validation loss for 5 consecutive epochs.\n",
        "model.fit(x_train, y_train, epochs=50, callbacks=[callback],validation_data=(x_val, y_val))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 34, 300)           4004100   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 100)               160400    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 3)                 303       \n",
            "=================================================================\n",
            "Total params: 4,164,803\n",
            "Trainable params: 160,703\n",
            "Non-trainable params: 4,004,100\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/50\n",
            "321/321 [==============================] - 2s 8ms/step - loss: 0.6858 - acc: 0.7263 - val_loss: 0.5797 - val_acc: 0.7719\n",
            "Epoch 2/50\n",
            "321/321 [==============================] - 2s 6ms/step - loss: 0.5641 - acc: 0.7766 - val_loss: 0.5887 - val_acc: 0.7687\n",
            "Epoch 3/50\n",
            "321/321 [==============================] - 2s 6ms/step - loss: 0.5298 - acc: 0.7865 - val_loss: 0.5142 - val_acc: 0.7964\n",
            "Epoch 4/50\n",
            "321/321 [==============================] - 2s 6ms/step - loss: 0.4999 - acc: 0.7957 - val_loss: 0.5245 - val_acc: 0.7873\n",
            "Epoch 5/50\n",
            "321/321 [==============================] - 2s 6ms/step - loss: 0.4779 - acc: 0.8058 - val_loss: 0.5388 - val_acc: 0.7864\n",
            "Epoch 6/50\n",
            "321/321 [==============================] - 2s 6ms/step - loss: 0.4633 - acc: 0.8123 - val_loss: 0.5161 - val_acc: 0.7955\n",
            "Epoch 7/50\n",
            "321/321 [==============================] - 2s 6ms/step - loss: 0.4463 - acc: 0.8235 - val_loss: 0.5063 - val_acc: 0.7992\n",
            "Epoch 8/50\n",
            "321/321 [==============================] - 2s 6ms/step - loss: 0.4269 - acc: 0.8282 - val_loss: 0.5276 - val_acc: 0.7828\n",
            "Epoch 9/50\n",
            "321/321 [==============================] - 2s 6ms/step - loss: 0.4053 - acc: 0.8348 - val_loss: 0.5533 - val_acc: 0.7864\n",
            "Epoch 10/50\n",
            "321/321 [==============================] - 2s 6ms/step - loss: 0.3864 - acc: 0.8465 - val_loss: 0.5005 - val_acc: 0.8074\n",
            "Epoch 11/50\n",
            "321/321 [==============================] - 2s 6ms/step - loss: 0.3709 - acc: 0.8497 - val_loss: 0.5914 - val_acc: 0.7696\n",
            "Epoch 12/50\n",
            "321/321 [==============================] - 2s 6ms/step - loss: 0.3566 - acc: 0.8554 - val_loss: 0.5187 - val_acc: 0.8065\n",
            "Epoch 13/50\n",
            "321/321 [==============================] - 2s 6ms/step - loss: 0.3314 - acc: 0.8641 - val_loss: 0.5206 - val_acc: 0.8083\n",
            "Epoch 14/50\n",
            "321/321 [==============================] - 2s 6ms/step - loss: 0.3111 - acc: 0.8734 - val_loss: 0.5594 - val_acc: 0.7983\n",
            "Epoch 15/50\n",
            "321/321 [==============================] - 2s 6ms/step - loss: 0.2931 - acc: 0.8804 - val_loss: 0.5817 - val_acc: 0.8010\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc5482e1390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tpv_JfQZHsK5",
        "colab_type": "text"
      },
      "source": [
        "Model weights extraction "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_-Oe_kpCF1R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2032c886-16e4-4979-8459-19e60aab9c8b"
      },
      "source": [
        "for e in zip(model.layers[1].trainable_weights, model.layers[1].get_weights()):\n",
        "  print('Param %s:\\n%s' % (e[0],e[1]))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Param <tf.Variable 'lstm/lstm_cell/kernel:0' shape=(300, 400) dtype=float32, numpy=\n",
            "array([[ 0.08815192,  0.09716977,  0.00254296, ..., -0.09403526,\n",
            "        -0.01898826,  0.15587874],\n",
            "       [ 0.15319464, -0.02541624, -0.03523511, ..., -0.08448473,\n",
            "         0.02594964, -0.07609219],\n",
            "       [ 0.0238332 , -0.08978818,  0.00697285, ..., -0.12641865,\n",
            "         0.04266918, -0.100934  ],\n",
            "       ...,\n",
            "       [-0.12953196, -0.08304246,  0.01244843, ...,  0.06062976,\n",
            "         0.0079515 ,  0.08774588],\n",
            "       [-0.1479794 , -0.02860249, -0.02260115, ...,  0.17241871,\n",
            "         0.07891668, -0.03710394],\n",
            "       [ 0.00805102, -0.04112032,  0.0064938 , ...,  0.06257927,\n",
            "         0.1095733 ,  0.04310419]], dtype=float32)>:\n",
            "[[ 0.08815192  0.09716977  0.00254296 ... -0.09403526 -0.01898826\n",
            "   0.15587874]\n",
            " [ 0.15319464 -0.02541624 -0.03523511 ... -0.08448473  0.02594964\n",
            "  -0.07609219]\n",
            " [ 0.0238332  -0.08978818  0.00697285 ... -0.12641865  0.04266918\n",
            "  -0.100934  ]\n",
            " ...\n",
            " [-0.12953196 -0.08304246  0.01244843 ...  0.06062976  0.0079515\n",
            "   0.08774588]\n",
            " [-0.1479794  -0.02860249 -0.02260115 ...  0.17241871  0.07891668\n",
            "  -0.03710394]\n",
            " [ 0.00805102 -0.04112032  0.0064938  ...  0.06257927  0.1095733\n",
            "   0.04310419]]\n",
            "Param <tf.Variable 'lstm/lstm_cell/recurrent_kernel:0' shape=(100, 400) dtype=float32, numpy=\n",
            "array([[-0.03604534, -0.05412281,  0.03882144, ...,  0.02096531,\n",
            "         0.01362227,  0.01708672],\n",
            "       [-0.01848522, -0.02926143,  0.1004068 , ..., -0.04001034,\n",
            "         0.04526246, -0.00614301],\n",
            "       [ 0.1763958 , -0.18089712,  0.06248463, ...,  0.01820156,\n",
            "         0.04335662, -0.07093368],\n",
            "       ...,\n",
            "       [-0.10124102, -0.03476474, -0.01055899, ...,  0.03683693,\n",
            "        -0.04283135, -0.01325749],\n",
            "       [ 0.09986255, -0.12122653,  0.20585509, ...,  0.11226439,\n",
            "         0.07077768,  0.04790965],\n",
            "       [-0.01882197,  0.00810068, -0.01761138, ...,  0.00069007,\n",
            "        -0.0551091 , -0.14847419]], dtype=float32)>:\n",
            "[[-0.03604534 -0.05412281  0.03882144 ...  0.02096531  0.01362227\n",
            "   0.01708672]\n",
            " [-0.01848522 -0.02926143  0.1004068  ... -0.04001034  0.04526246\n",
            "  -0.00614301]\n",
            " [ 0.1763958  -0.18089712  0.06248463 ...  0.01820156  0.04335662\n",
            "  -0.07093368]\n",
            " ...\n",
            " [-0.10124102 -0.03476474 -0.01055899 ...  0.03683693 -0.04283135\n",
            "  -0.01325749]\n",
            " [ 0.09986255 -0.12122653  0.20585509 ...  0.11226439  0.07077768\n",
            "   0.04790965]\n",
            " [-0.01882197  0.00810068 -0.01761138 ...  0.00069007 -0.0551091\n",
            "  -0.14847419]]\n",
            "Param <tf.Variable 'lstm/lstm_cell/bias:0' shape=(400,) dtype=float32, numpy=\n",
            "array([-2.70161349e-02,  8.00329894e-02, -1.52327716e-02,  2.51141358e-02,\n",
            "        1.07914461e-02,  6.27404675e-02,  7.40214810e-02, -6.59125969e-02,\n",
            "       -8.50720480e-02, -3.11432499e-02, -9.65139419e-02, -1.27770916e-01,\n",
            "       -2.95898374e-02,  3.47359404e-02, -6.75753225e-03,  1.31088689e-01,\n",
            "        1.13966521e-02,  8.37400109e-02,  3.36032249e-02, -8.45348537e-02,\n",
            "       -4.31917310e-02,  7.65659139e-02,  4.82550338e-02, -7.61931613e-02,\n",
            "        8.34793411e-03, -1.92415982e-01, -1.55519605e-01, -1.50832310e-01,\n",
            "       -8.31710771e-02, -1.67765990e-02, -1.21135354e-01, -1.01545371e-01,\n",
            "       -1.06919356e-01,  1.73285548e-02, -3.61575931e-02, -5.50992563e-02,\n",
            "       -5.79999909e-02,  4.92141675e-03, -8.68441612e-02, -1.02761649e-02,\n",
            "       -1.20059796e-01,  7.74845257e-02, -1.35903612e-01,  1.27087887e-02,\n",
            "        5.30601405e-02,  5.27204163e-02, -1.37256384e-01, -7.67250732e-02,\n",
            "       -9.11145955e-02, -5.44387149e-03, -1.54481418e-02, -6.80358186e-02,\n",
            "       -1.42214686e-01,  1.02023706e-01, -5.41992411e-02, -1.45609844e-02,\n",
            "       -4.90096323e-02,  2.04835795e-02, -1.46425560e-01, -7.98657257e-03,\n",
            "        6.82273926e-03, -1.47492707e-01, -1.70631334e-02, -3.14233042e-02,\n",
            "       -9.03815776e-02,  3.65394875e-02, -7.27536753e-02, -2.92213243e-02,\n",
            "       -3.79897654e-02, -4.25832570e-02, -4.74696755e-02,  5.28724343e-02,\n",
            "        1.07756086e-01, -1.33221177e-02, -1.24294028e-01,  9.20911580e-02,\n",
            "       -1.75506659e-02, -2.21386310e-02, -2.74293963e-02, -5.18741719e-02,\n",
            "       -5.86201772e-02,  8.50031823e-02, -6.22010119e-02, -5.92188835e-02,\n",
            "        1.06824674e-02, -1.39611751e-01, -1.63038447e-01,  3.24073341e-03,\n",
            "       -6.81951344e-02,  3.49456370e-02,  1.90200537e-01, -1.87025052e-02,\n",
            "        7.94067383e-02,  5.31362034e-02, -8.82057920e-02,  6.83208480e-02,\n",
            "       -4.39090729e-02, -1.54718859e-02, -9.82329343e-03, -6.00392558e-02,\n",
            "        9.66084719e-01,  9.19065535e-01,  1.05663657e+00,  1.01188624e+00,\n",
            "        1.03983951e+00,  9.84829426e-01,  1.06448412e+00,  9.52839911e-01,\n",
            "        1.00757265e+00,  9.46671844e-01,  1.01772726e+00,  1.00910199e+00,\n",
            "        9.90869343e-01,  9.19371307e-01,  1.06804907e+00,  9.37683582e-01,\n",
            "        1.05141568e+00,  9.85715270e-01,  9.53561008e-01,  1.01543367e+00,\n",
            "        1.00071561e+00,  1.03967226e+00,  9.73354816e-01,  1.03605628e+00,\n",
            "        1.03647029e+00,  9.65647936e-01,  9.18034732e-01,  9.33543682e-01,\n",
            "        9.95745480e-01,  9.84303653e-01,  9.94584322e-01,  9.74806964e-01,\n",
            "        1.01565182e+00,  9.34741318e-01,  1.03993261e+00,  9.44569647e-01,\n",
            "        9.79780316e-01,  9.47683096e-01,  1.04947913e+00,  9.20099854e-01,\n",
            "        9.85043406e-01,  9.91745949e-01,  9.98593271e-01,  1.04884923e+00,\n",
            "        1.01757669e+00,  1.10198665e+00,  1.03210676e+00,  9.81847167e-01,\n",
            "        9.93329525e-01,  9.45983052e-01,  1.01966977e+00,  1.03082883e+00,\n",
            "        1.00979757e+00,  9.93549466e-01,  1.03384900e+00,  1.07449567e+00,\n",
            "        1.01208687e+00,  9.77164805e-01,  9.82048690e-01,  1.04698336e+00,\n",
            "        1.08386362e+00,  9.98103380e-01,  1.00601184e+00,  9.56998587e-01,\n",
            "        9.98665810e-01,  1.00950301e+00,  1.01556182e+00,  1.00587726e+00,\n",
            "        1.01177621e+00,  1.05547166e+00,  9.77039099e-01,  1.02218318e+00,\n",
            "        9.67607915e-01,  9.92823124e-01,  1.05634081e+00,  9.86685276e-01,\n",
            "        9.64973450e-01,  9.72593665e-01,  9.89122808e-01,  9.86081541e-01,\n",
            "        9.38502312e-01,  8.77174377e-01,  1.03497076e+00,  9.99808848e-01,\n",
            "        9.80063736e-01,  1.03396785e+00,  9.64245915e-01,  9.36654270e-01,\n",
            "        1.00660312e+00,  9.27006483e-01,  9.11434889e-01,  9.56371486e-01,\n",
            "        9.74238038e-01,  9.98495519e-01,  1.00887561e+00,  9.23227072e-01,\n",
            "        9.19974506e-01,  1.01348865e+00,  1.03205979e+00,  1.01436543e+00,\n",
            "        1.07395547e-02, -6.68318849e-03, -7.18146469e-03, -1.56937540e-02,\n",
            "       -3.21967900e-02, -1.14436010e-02, -2.63047609e-02,  4.93857893e-04,\n",
            "       -2.95277196e-03, -2.44550942e-03, -1.80603396e-02, -2.98990449e-03,\n",
            "       -1.72148235e-02, -1.49140945e-02, -3.00313197e-02, -2.10880358e-02,\n",
            "        6.21926785e-03,  3.14843170e-02,  1.86337177e-02, -4.95002195e-02,\n",
            "       -1.71103273e-02, -3.38738151e-02, -1.59423649e-02,  2.51209047e-02,\n",
            "       -3.10876016e-02, -1.24082314e-02,  2.48395670e-02, -1.18668722e-02,\n",
            "        1.60942171e-02,  1.91236958e-02,  2.17728317e-02,  1.83566660e-02,\n",
            "       -3.29911523e-02,  4.87809591e-02, -2.21977886e-02,  1.96221285e-02,\n",
            "        2.31886003e-03,  2.07821354e-02,  1.84004046e-02, -3.12611833e-02,\n",
            "       -2.92961299e-02,  2.21344624e-02,  3.37298065e-02, -5.93064725e-03,\n",
            "        1.24475947e-02, -2.69214138e-02, -2.84671094e-02,  1.48149692e-02,\n",
            "       -2.31081750e-02, -3.31183821e-02,  1.81388687e-02, -1.99810211e-02,\n",
            "       -8.04804638e-03, -5.79545461e-02, -3.68044246e-03,  2.72401031e-02,\n",
            "       -1.80669837e-02, -2.57823430e-02, -1.52290333e-03,  4.38032299e-03,\n",
            "        6.90301764e-04,  6.10819226e-03,  1.10761533e-02,  1.44621516e-02,\n",
            "       -2.21830932e-03, -4.94385837e-03,  8.08211509e-03, -2.71850061e-02,\n",
            "       -2.26877946e-02, -1.87138678e-04, -9.63091291e-03,  1.49338143e-02,\n",
            "        2.42097471e-02, -2.32568327e-02, -2.57661063e-02,  3.34982648e-02,\n",
            "        3.59800830e-03,  1.52904084e-02,  3.58464569e-02, -3.00724488e-02,\n",
            "       -3.08116544e-02,  5.10307960e-04,  1.94720216e-02,  3.89408506e-02,\n",
            "        1.57628255e-03,  2.85023563e-02,  5.26757119e-03,  2.25022808e-02,\n",
            "       -8.26922804e-03,  4.73673362e-03, -1.88209601e-02, -6.68463577e-03,\n",
            "       -1.80727039e-02, -1.86212324e-02,  2.24946197e-02,  2.87200715e-02,\n",
            "       -2.55138092e-02,  2.90464237e-03, -8.19093920e-03,  2.63141021e-02,\n",
            "        2.07933784e-02,  1.14691772e-01, -9.80175287e-02, -7.92283332e-04,\n",
            "       -3.62983383e-02,  5.09615354e-02,  3.25428732e-02,  3.28699946e-02,\n",
            "       -9.57610905e-02, -2.57369187e-02, -1.22530637e-02, -2.34914832e-02,\n",
            "        5.06476723e-02, -4.58931830e-03,  2.05462147e-02,  5.97183816e-02,\n",
            "        9.90635809e-03,  4.25709523e-02,  4.04932424e-02, -2.59503257e-02,\n",
            "        1.69338249e-02,  8.10377076e-02,  1.33639500e-01, -7.05462042e-03,\n",
            "        1.80556979e-02, -6.38509020e-02, -5.43792509e-02, -2.73971632e-02,\n",
            "       -1.28587596e-02, -1.70449223e-02, -3.29631008e-02, -2.64007486e-02,\n",
            "       -5.19510545e-03,  6.06718706e-03, -1.33162346e-02, -2.94211321e-02,\n",
            "       -3.85839343e-02,  3.91750922e-03, -4.91799228e-02, -4.60687988e-02,\n",
            "       -4.69995588e-02,  1.11741148e-01,  1.95727777e-02, -8.13208800e-03,\n",
            "       -1.61030069e-02,  1.76498313e-02, -1.80791076e-02, -1.49875414e-02,\n",
            "       -3.67752910e-02,  3.47946435e-02, -2.32339986e-02, -9.04234312e-03,\n",
            "        1.25731165e-02,  4.72425781e-02, -3.11717093e-02, -7.53609091e-03,\n",
            "       -3.48891271e-03,  3.33334841e-02, -3.40893902e-02,  3.74669135e-02,\n",
            "        2.82138363e-02,  1.18972519e-02,  5.62964054e-03, -6.15402963e-03,\n",
            "       -3.67808230e-02,  7.75322765e-02, -9.84703656e-03,  1.96513273e-02,\n",
            "       -1.87249656e-03,  2.47403514e-03, -3.00408602e-02, -7.39473733e-04,\n",
            "        6.25483543e-02, -1.62444694e-03,  3.55413035e-02,  8.61506015e-02,\n",
            "        1.22281043e-02, -5.29846847e-02, -7.09511526e-03,  1.42240582e-03,\n",
            "        2.43061949e-02, -4.88833152e-03,  2.06082482e-02, -2.92809084e-02,\n",
            "        4.81321290e-02,  3.07009742e-02, -6.45010769e-02, -6.64546899e-03,\n",
            "       -4.84899208e-02, -5.12273461e-02,  1.75731689e-01,  2.76965788e-03,\n",
            "        2.86835842e-02,  3.70229781e-02, -6.43696258e-05,  9.55044180e-02,\n",
            "       -5.49333356e-02, -1.86167862e-02,  1.13111529e-02, -4.35490645e-02],\n",
            "      dtype=float32)>:\n",
            "[-2.70161349e-02  8.00329894e-02 -1.52327716e-02  2.51141358e-02\n",
            "  1.07914461e-02  6.27404675e-02  7.40214810e-02 -6.59125969e-02\n",
            " -8.50720480e-02 -3.11432499e-02 -9.65139419e-02 -1.27770916e-01\n",
            " -2.95898374e-02  3.47359404e-02 -6.75753225e-03  1.31088689e-01\n",
            "  1.13966521e-02  8.37400109e-02  3.36032249e-02 -8.45348537e-02\n",
            " -4.31917310e-02  7.65659139e-02  4.82550338e-02 -7.61931613e-02\n",
            "  8.34793411e-03 -1.92415982e-01 -1.55519605e-01 -1.50832310e-01\n",
            " -8.31710771e-02 -1.67765990e-02 -1.21135354e-01 -1.01545371e-01\n",
            " -1.06919356e-01  1.73285548e-02 -3.61575931e-02 -5.50992563e-02\n",
            " -5.79999909e-02  4.92141675e-03 -8.68441612e-02 -1.02761649e-02\n",
            " -1.20059796e-01  7.74845257e-02 -1.35903612e-01  1.27087887e-02\n",
            "  5.30601405e-02  5.27204163e-02 -1.37256384e-01 -7.67250732e-02\n",
            " -9.11145955e-02 -5.44387149e-03 -1.54481418e-02 -6.80358186e-02\n",
            " -1.42214686e-01  1.02023706e-01 -5.41992411e-02 -1.45609844e-02\n",
            " -4.90096323e-02  2.04835795e-02 -1.46425560e-01 -7.98657257e-03\n",
            "  6.82273926e-03 -1.47492707e-01 -1.70631334e-02 -3.14233042e-02\n",
            " -9.03815776e-02  3.65394875e-02 -7.27536753e-02 -2.92213243e-02\n",
            " -3.79897654e-02 -4.25832570e-02 -4.74696755e-02  5.28724343e-02\n",
            "  1.07756086e-01 -1.33221177e-02 -1.24294028e-01  9.20911580e-02\n",
            " -1.75506659e-02 -2.21386310e-02 -2.74293963e-02 -5.18741719e-02\n",
            " -5.86201772e-02  8.50031823e-02 -6.22010119e-02 -5.92188835e-02\n",
            "  1.06824674e-02 -1.39611751e-01 -1.63038447e-01  3.24073341e-03\n",
            " -6.81951344e-02  3.49456370e-02  1.90200537e-01 -1.87025052e-02\n",
            "  7.94067383e-02  5.31362034e-02 -8.82057920e-02  6.83208480e-02\n",
            " -4.39090729e-02 -1.54718859e-02 -9.82329343e-03 -6.00392558e-02\n",
            "  9.66084719e-01  9.19065535e-01  1.05663657e+00  1.01188624e+00\n",
            "  1.03983951e+00  9.84829426e-01  1.06448412e+00  9.52839911e-01\n",
            "  1.00757265e+00  9.46671844e-01  1.01772726e+00  1.00910199e+00\n",
            "  9.90869343e-01  9.19371307e-01  1.06804907e+00  9.37683582e-01\n",
            "  1.05141568e+00  9.85715270e-01  9.53561008e-01  1.01543367e+00\n",
            "  1.00071561e+00  1.03967226e+00  9.73354816e-01  1.03605628e+00\n",
            "  1.03647029e+00  9.65647936e-01  9.18034732e-01  9.33543682e-01\n",
            "  9.95745480e-01  9.84303653e-01  9.94584322e-01  9.74806964e-01\n",
            "  1.01565182e+00  9.34741318e-01  1.03993261e+00  9.44569647e-01\n",
            "  9.79780316e-01  9.47683096e-01  1.04947913e+00  9.20099854e-01\n",
            "  9.85043406e-01  9.91745949e-01  9.98593271e-01  1.04884923e+00\n",
            "  1.01757669e+00  1.10198665e+00  1.03210676e+00  9.81847167e-01\n",
            "  9.93329525e-01  9.45983052e-01  1.01966977e+00  1.03082883e+00\n",
            "  1.00979757e+00  9.93549466e-01  1.03384900e+00  1.07449567e+00\n",
            "  1.01208687e+00  9.77164805e-01  9.82048690e-01  1.04698336e+00\n",
            "  1.08386362e+00  9.98103380e-01  1.00601184e+00  9.56998587e-01\n",
            "  9.98665810e-01  1.00950301e+00  1.01556182e+00  1.00587726e+00\n",
            "  1.01177621e+00  1.05547166e+00  9.77039099e-01  1.02218318e+00\n",
            "  9.67607915e-01  9.92823124e-01  1.05634081e+00  9.86685276e-01\n",
            "  9.64973450e-01  9.72593665e-01  9.89122808e-01  9.86081541e-01\n",
            "  9.38502312e-01  8.77174377e-01  1.03497076e+00  9.99808848e-01\n",
            "  9.80063736e-01  1.03396785e+00  9.64245915e-01  9.36654270e-01\n",
            "  1.00660312e+00  9.27006483e-01  9.11434889e-01  9.56371486e-01\n",
            "  9.74238038e-01  9.98495519e-01  1.00887561e+00  9.23227072e-01\n",
            "  9.19974506e-01  1.01348865e+00  1.03205979e+00  1.01436543e+00\n",
            "  1.07395547e-02 -6.68318849e-03 -7.18146469e-03 -1.56937540e-02\n",
            " -3.21967900e-02 -1.14436010e-02 -2.63047609e-02  4.93857893e-04\n",
            " -2.95277196e-03 -2.44550942e-03 -1.80603396e-02 -2.98990449e-03\n",
            " -1.72148235e-02 -1.49140945e-02 -3.00313197e-02 -2.10880358e-02\n",
            "  6.21926785e-03  3.14843170e-02  1.86337177e-02 -4.95002195e-02\n",
            " -1.71103273e-02 -3.38738151e-02 -1.59423649e-02  2.51209047e-02\n",
            " -3.10876016e-02 -1.24082314e-02  2.48395670e-02 -1.18668722e-02\n",
            "  1.60942171e-02  1.91236958e-02  2.17728317e-02  1.83566660e-02\n",
            " -3.29911523e-02  4.87809591e-02 -2.21977886e-02  1.96221285e-02\n",
            "  2.31886003e-03  2.07821354e-02  1.84004046e-02 -3.12611833e-02\n",
            " -2.92961299e-02  2.21344624e-02  3.37298065e-02 -5.93064725e-03\n",
            "  1.24475947e-02 -2.69214138e-02 -2.84671094e-02  1.48149692e-02\n",
            " -2.31081750e-02 -3.31183821e-02  1.81388687e-02 -1.99810211e-02\n",
            " -8.04804638e-03 -5.79545461e-02 -3.68044246e-03  2.72401031e-02\n",
            " -1.80669837e-02 -2.57823430e-02 -1.52290333e-03  4.38032299e-03\n",
            "  6.90301764e-04  6.10819226e-03  1.10761533e-02  1.44621516e-02\n",
            " -2.21830932e-03 -4.94385837e-03  8.08211509e-03 -2.71850061e-02\n",
            " -2.26877946e-02 -1.87138678e-04 -9.63091291e-03  1.49338143e-02\n",
            "  2.42097471e-02 -2.32568327e-02 -2.57661063e-02  3.34982648e-02\n",
            "  3.59800830e-03  1.52904084e-02  3.58464569e-02 -3.00724488e-02\n",
            " -3.08116544e-02  5.10307960e-04  1.94720216e-02  3.89408506e-02\n",
            "  1.57628255e-03  2.85023563e-02  5.26757119e-03  2.25022808e-02\n",
            " -8.26922804e-03  4.73673362e-03 -1.88209601e-02 -6.68463577e-03\n",
            " -1.80727039e-02 -1.86212324e-02  2.24946197e-02  2.87200715e-02\n",
            " -2.55138092e-02  2.90464237e-03 -8.19093920e-03  2.63141021e-02\n",
            "  2.07933784e-02  1.14691772e-01 -9.80175287e-02 -7.92283332e-04\n",
            " -3.62983383e-02  5.09615354e-02  3.25428732e-02  3.28699946e-02\n",
            " -9.57610905e-02 -2.57369187e-02 -1.22530637e-02 -2.34914832e-02\n",
            "  5.06476723e-02 -4.58931830e-03  2.05462147e-02  5.97183816e-02\n",
            "  9.90635809e-03  4.25709523e-02  4.04932424e-02 -2.59503257e-02\n",
            "  1.69338249e-02  8.10377076e-02  1.33639500e-01 -7.05462042e-03\n",
            "  1.80556979e-02 -6.38509020e-02 -5.43792509e-02 -2.73971632e-02\n",
            " -1.28587596e-02 -1.70449223e-02 -3.29631008e-02 -2.64007486e-02\n",
            " -5.19510545e-03  6.06718706e-03 -1.33162346e-02 -2.94211321e-02\n",
            " -3.85839343e-02  3.91750922e-03 -4.91799228e-02 -4.60687988e-02\n",
            " -4.69995588e-02  1.11741148e-01  1.95727777e-02 -8.13208800e-03\n",
            " -1.61030069e-02  1.76498313e-02 -1.80791076e-02 -1.49875414e-02\n",
            " -3.67752910e-02  3.47946435e-02 -2.32339986e-02 -9.04234312e-03\n",
            "  1.25731165e-02  4.72425781e-02 -3.11717093e-02 -7.53609091e-03\n",
            " -3.48891271e-03  3.33334841e-02 -3.40893902e-02  3.74669135e-02\n",
            "  2.82138363e-02  1.18972519e-02  5.62964054e-03 -6.15402963e-03\n",
            " -3.67808230e-02  7.75322765e-02 -9.84703656e-03  1.96513273e-02\n",
            " -1.87249656e-03  2.47403514e-03 -3.00408602e-02 -7.39473733e-04\n",
            "  6.25483543e-02 -1.62444694e-03  3.55413035e-02  8.61506015e-02\n",
            "  1.22281043e-02 -5.29846847e-02 -7.09511526e-03  1.42240582e-03\n",
            "  2.43061949e-02 -4.88833152e-03  2.06082482e-02 -2.92809084e-02\n",
            "  4.81321290e-02  3.07009742e-02 -6.45010769e-02 -6.64546899e-03\n",
            " -4.84899208e-02 -5.12273461e-02  1.75731689e-01  2.76965788e-03\n",
            "  2.86835842e-02  3.70229781e-02 -6.43696258e-05  9.55044180e-02\n",
            " -5.49333356e-02 -1.86167862e-02  1.13111529e-02 -4.35490645e-02]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_GkwGzWEdhm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "units = 100\n",
        "W = model.layers[1].get_weights()[0]\n",
        "U = model.layers[1].get_weights()[1]\n",
        "b = model.layers[1].get_weights()[2]\n",
        "\n",
        "W_i = W[:, :units]\n",
        "W_f = W[:, units: units * 2]\n",
        "W_c = W[:, units * 2: units * 3]\n",
        "W_o = W[:, units * 3:]\n",
        "\n",
        "U_i = U[:, :units]\n",
        "U_f = U[:, units: units * 2]\n",
        "U_c = U[:, units * 2: units * 3]\n",
        "U_o = U[:, units * 3:]\n",
        "\n",
        "b_i = b[:units]\n",
        "b_f = b[units: units * 2]\n",
        "b_c = b[units * 2: units * 3]\n",
        "b_o = b[units * 3:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQKIYp-uEeB-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f746af93-ee7c-48c3-ae13-28411fcf54f5"
      },
      "source": [
        "print (W.shape, U.shape, b.shape)\n",
        "print (W_i.shape, W_f.shape, W_c.shape, W_o.shape)\n",
        "print (U_i.shape,U_f.shape,U_c.shape,U_o.shape,)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(300, 400) (100, 400) (400,)\n",
            "(300, 100) (300, 100) (300, 100) (300, 100)\n",
            "(100, 100) (100, 100) (100, 100) (100, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJBfdWDqE9aZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ksu7TbWjCd_0",
        "colab_type": "code",
        "outputId": "676c4b4e-dc07-4847-9df9-3263ce2ebbb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "model.evaluate(x_test, y_test, batch_size = 128)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5102 - acc: 0.7987\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.510235071182251, 0.7987249493598938]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCCEAQBb4BSi",
        "colab_type": "text"
      },
      "source": [
        "Tips:\n",
        "\n",
        "1. Can save model when accuracy improve \n",
        "2. Earlystoping can also be used if validation accuracy loss is not decreaing or validation accuracy is not increasing. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JODjz49xzeXn",
        "colab_type": "text"
      },
      "source": [
        "CNN and LSTM based model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6PnWzHIzgPr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def CNN_LSTM_model(num_words,EMBEDDING_DIM,embedding_weights,max_sequence_length,labels_index):\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(num_words, EMBEDDING_DIM, weights=[embedding_weights],\n",
        "                      input_length=max_sequence_length,\n",
        "                     trainable=False))\n",
        "  model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
        "  model.add(MaxPooling1D(pool_size=2))\n",
        "  model.add(LSTM(100,dropout=0.2))\n",
        "  model.add(Dense(labels_index, activation='sigmoid'))\n",
        "  print(model.summary())\n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "                optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-3),\n",
        "                metrics=['acc'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fmz3Tu8i7RTD",
        "colab_type": "code",
        "outputId": "77580969-a4cd-4252-e455-69b39b24abff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        }
      },
      "source": [
        "model = CNN_LSTM_model(num_words, EMBEDDING_DIM,embedding_weights,MAX_SEQUENCE_LENGTH,len(list(tweet_text['airline_sentiment'].unique())))\n",
        "#model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=50, batch_size=128)\n",
        "callback = EarlyStopping(monitor='val_loss', patience=5,restore_best_weights=True,mode=\"min\")\n",
        "# This callback will stop the training when there is no improvement in\n",
        "# the validation loss for 5 consecutive epochs.\n",
        "model.fit(x_train, y_train, epochs=50, callbacks=[callback],validation_data=(x_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_27\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_27 (Embedding)     (None, 34, 300)           4004100   \n",
            "_________________________________________________________________\n",
            "conv1d_6 (Conv1D)            (None, 34, 32)            28832     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_4 (MaxPooling1 (None, 17, 32)            0         \n",
            "_________________________________________________________________\n",
            "lstm_22 (LSTM)               (None, 100)               53200     \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 3)                 303       \n",
            "=================================================================\n",
            "Total params: 4,086,435\n",
            "Trainable params: 82,335\n",
            "Non-trainable params: 4,004,100\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/50\n",
            "321/321 [==============================] - 2s 7ms/step - loss: 0.6964 - acc: 0.7148 - val_loss: 0.5650 - val_acc: 0.7896\n",
            "Epoch 2/50\n",
            "321/321 [==============================] - 2s 6ms/step - loss: 0.5519 - acc: 0.7811 - val_loss: 0.5366 - val_acc: 0.7919\n",
            "Epoch 3/50\n",
            "321/321 [==============================] - 2s 7ms/step - loss: 0.5107 - acc: 0.7946 - val_loss: 0.4747 - val_acc: 0.8074\n",
            "Epoch 4/50\n",
            "321/321 [==============================] - 2s 6ms/step - loss: 0.4793 - acc: 0.8125 - val_loss: 0.5223 - val_acc: 0.8024\n",
            "Epoch 5/50\n",
            "321/321 [==============================] - 2s 6ms/step - loss: 0.4532 - acc: 0.8207 - val_loss: 0.6624 - val_acc: 0.7341\n",
            "Epoch 6/50\n",
            "321/321 [==============================] - 2s 6ms/step - loss: 0.4312 - acc: 0.8298 - val_loss: 0.4667 - val_acc: 0.8188\n",
            "Epoch 7/50\n",
            "321/321 [==============================] - 2s 6ms/step - loss: 0.4052 - acc: 0.8454 - val_loss: 0.4786 - val_acc: 0.8179\n",
            "Epoch 8/50\n",
            "321/321 [==============================] - 2s 6ms/step - loss: 0.3866 - acc: 0.8507 - val_loss: 0.4826 - val_acc: 0.8197\n",
            "Epoch 9/50\n",
            "321/321 [==============================] - 2s 6ms/step - loss: 0.3625 - acc: 0.8596 - val_loss: 0.5090 - val_acc: 0.8169\n",
            "Epoch 10/50\n",
            "321/321 [==============================] - 2s 6ms/step - loss: 0.3438 - acc: 0.8701 - val_loss: 0.5760 - val_acc: 0.7769\n",
            "Epoch 11/50\n",
            "321/321 [==============================] - 2s 6ms/step - loss: 0.3243 - acc: 0.8760 - val_loss: 0.5296 - val_acc: 0.7992\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3ed937a3c8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pOURE3-7eHL",
        "colab_type": "code",
        "outputId": "b219bd74-cf33-4d31-89c9-78ae917249aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "model.evaluate(x_test, y_test, batch_size = 128)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5046 - acc: 0.8010\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5045666694641113, 0.8010018467903137]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mKQkbhy721J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-9yySh69UXk",
        "colab_type": "text"
      },
      "source": [
        "GRU based model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cuXh4859X4f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def GRU_model(num_words,EMBEDDING_DIM,embedding_weights,max_sequence_length,labels_index):\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(num_words, EMBEDDING_DIM, weights=[embedding_weights],\n",
        "                      input_length=max_sequence_length,\n",
        "                     trainable=False))\n",
        "  model.add(GRU(100,dropout=0.2))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(labels_index, activation='sigmoid'))\n",
        "  print(model.summary())\n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "                optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-3),\n",
        "                metrics=['acc'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQ7iFm1D9bqs",
        "colab_type": "code",
        "outputId": "3d0580c1-fdd1-4f51-ef0a-a3658083784f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "model = GRU_model(num_words, EMBEDDING_DIM,embedding_weights,MAX_SEQUENCE_LENGTH,len(list(tweet_text['airline_sentiment'].unique())))\n",
        "#model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=50, batch_size=128)\n",
        "callback = EarlyStopping(monitor='val_loss', patience=5,restore_best_weights=True,mode=\"min\")\n",
        "# This callback will stop the training when there is no improvement in\n",
        "# the validation loss for 5 consecutive epochs.\n",
        "model.fit(x_train, y_train, epochs=50, callbacks=[callback],validation_data=(x_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_26\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_26 (Embedding)     (None, 34, 300)           4004100   \n",
            "_________________________________________________________________\n",
            "gru_3 (GRU)                  (None, 100)               120600    \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 3)                 303       \n",
            "=================================================================\n",
            "Total params: 4,125,003\n",
            "Trainable params: 120,903\n",
            "Non-trainable params: 4,004,100\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/50\n",
            "321/321 [==============================] - 2s 6ms/step - loss: 0.7009 - acc: 0.7129 - val_loss: 0.5401 - val_acc: 0.7901\n",
            "Epoch 2/50\n",
            "321/321 [==============================] - 2s 6ms/step - loss: 0.5588 - acc: 0.7734 - val_loss: 0.5072 - val_acc: 0.8001\n",
            "Epoch 3/50\n",
            "321/321 [==============================] - 2s 6ms/step - loss: 0.5287 - acc: 0.7875 - val_loss: 0.4881 - val_acc: 0.8056\n",
            "Epoch 4/50\n",
            "321/321 [==============================] - 2s 6ms/step - loss: 0.4990 - acc: 0.8020 - val_loss: 0.4901 - val_acc: 0.8087\n",
            "Epoch 5/50\n",
            "321/321 [==============================] - 2s 6ms/step - loss: 0.4769 - acc: 0.8099 - val_loss: 0.4920 - val_acc: 0.8128\n",
            "Epoch 6/50\n",
            "321/321 [==============================] - 2s 6ms/step - loss: 0.4626 - acc: 0.8169 - val_loss: 0.4651 - val_acc: 0.8197\n",
            "Epoch 7/50\n",
            "321/321 [==============================] - 2s 6ms/step - loss: 0.4475 - acc: 0.8211 - val_loss: 0.4775 - val_acc: 0.8179\n",
            "Epoch 8/50\n",
            "321/321 [==============================] - 2s 6ms/step - loss: 0.4329 - acc: 0.8283 - val_loss: 0.4784 - val_acc: 0.8138\n",
            "Epoch 9/50\n",
            "321/321 [==============================] - 2s 5ms/step - loss: 0.4157 - acc: 0.8350 - val_loss: 0.5203 - val_acc: 0.7914\n",
            "Epoch 10/50\n",
            "321/321 [==============================] - 2s 5ms/step - loss: 0.3945 - acc: 0.8404 - val_loss: 0.4749 - val_acc: 0.8260\n",
            "Epoch 11/50\n",
            "321/321 [==============================] - 2s 5ms/step - loss: 0.3767 - acc: 0.8530 - val_loss: 0.4891 - val_acc: 0.8242\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3edb2834a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMEuRBkS9ndM",
        "colab_type": "code",
        "outputId": "c95a3c0f-1a79-4afd-d427-9a5979b582cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "model.evaluate(x_test, y_test, batch_size = 128)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4914 - acc: 0.8019\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.49135515093803406, 0.8019125461578369]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IN9wMrLqHUMq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-ll5H5HI3im",
        "colab_type": "text"
      },
      "source": [
        "Bidirectional based model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjCAfx2sI8HF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Bidirectional_model(num_words,EMBEDDING_DIM,embedding_weights,max_sequence_length,labels_index):\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(num_words, EMBEDDING_DIM, weights=[embedding_weights],\n",
        "                      input_length=max_sequence_length,\n",
        "                     trainable=False))\n",
        "  model.add(Bidirectional(LSTM(100,dropout=0.3)))\n",
        "  model.add(Dropout(0.3))\n",
        "  model.add(Dense(100, activation='tanh'))\n",
        "  model.add(Dense(labels_index, activation='sigmoid'))\n",
        "  print(model.summary())\n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "                optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-3),\n",
        "                metrics=['acc'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dAz9UIiJl83",
        "colab_type": "code",
        "outputId": "bf74e69e-d01c-40e4-eb70-cd5b6cd40217",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        }
      },
      "source": [
        "model = Bidirectional_model(num_words, EMBEDDING_DIM,embedding_weights,MAX_SEQUENCE_LENGTH,len(list(tweet_text['airline_sentiment'].unique())))\n",
        "#model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=50, batch_size=128)\n",
        "callback = EarlyStopping(monitor='val_loss', patience=5,restore_best_weights=True,mode=\"min\")\n",
        "# This callback will stop the training when there is no improvement in\n",
        "# the validation loss for 5 consecutive epochs.\n",
        "model.fit(x_train, y_train, epochs=50, callbacks=[callback],validation_data=(x_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_25\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_25 (Embedding)     (None, 34, 300)           4004100   \n",
            "_________________________________________________________________\n",
            "bidirectional_5 (Bidirection (None, 200)               320800    \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 100)               20100     \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 3)                 303       \n",
            "=================================================================\n",
            "Total params: 4,345,303\n",
            "Trainable params: 341,203\n",
            "Non-trainable params: 4,004,100\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/50\n",
            "321/321 [==============================] - 4s 11ms/step - loss: 0.6849 - acc: 0.7247 - val_loss: 0.5181 - val_acc: 0.7960\n",
            "Epoch 2/50\n",
            "321/321 [==============================] - 3s 10ms/step - loss: 0.5657 - acc: 0.7739 - val_loss: 0.5109 - val_acc: 0.7983\n",
            "Epoch 3/50\n",
            "321/321 [==============================] - 3s 10ms/step - loss: 0.5343 - acc: 0.7869 - val_loss: 0.5187 - val_acc: 0.7778\n",
            "Epoch 4/50\n",
            "321/321 [==============================] - 3s 9ms/step - loss: 0.5125 - acc: 0.7974 - val_loss: 0.4979 - val_acc: 0.8083\n",
            "Epoch 5/50\n",
            "321/321 [==============================] - 3s 9ms/step - loss: 0.4861 - acc: 0.8063 - val_loss: 0.4812 - val_acc: 0.8119\n",
            "Epoch 6/50\n",
            "321/321 [==============================] - 3s 9ms/step - loss: 0.4643 - acc: 0.8168 - val_loss: 0.4807 - val_acc: 0.8160\n",
            "Epoch 7/50\n",
            "321/321 [==============================] - 3s 9ms/step - loss: 0.4497 - acc: 0.8206 - val_loss: 0.4801 - val_acc: 0.8097\n",
            "Epoch 8/50\n",
            "321/321 [==============================] - 3s 9ms/step - loss: 0.4297 - acc: 0.8280 - val_loss: 0.5036 - val_acc: 0.8083\n",
            "Epoch 9/50\n",
            "321/321 [==============================] - 3s 9ms/step - loss: 0.4087 - acc: 0.8357 - val_loss: 0.6021 - val_acc: 0.7641\n",
            "Epoch 10/50\n",
            "321/321 [==============================] - 3s 9ms/step - loss: 0.3946 - acc: 0.8413 - val_loss: 0.5355 - val_acc: 0.8142\n",
            "Epoch 11/50\n",
            "321/321 [==============================] - 3s 10ms/step - loss: 0.3743 - acc: 0.8519 - val_loss: 0.4980 - val_acc: 0.8138\n",
            "Epoch 12/50\n",
            "321/321 [==============================] - 3s 9ms/step - loss: 0.3575 - acc: 0.8608 - val_loss: 0.5142 - val_acc: 0.8151\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3edbcaf2e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58UxpJfZJrc1",
        "colab_type": "code",
        "outputId": "50afb076-8d45-4132-fc20-ec9d1be8e504",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "model.evaluate(x_test, y_test, batch_size = 128)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4932 - acc: 0.8033\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.49323299527168274, 0.8032786846160889]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "beL01R9sHgUk",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iAuLk7KQjIr",
        "colab_type": "text"
      },
      "source": [
        "Bidirectional model with LearningRateScheduler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-A7onGbQm2B",
        "colab_type": "code",
        "outputId": "dc5b3f5b-5274-4506-ad13-bdf939221b92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "source": [
        "model = Bidirectional_model(num_words, EMBEDDING_DIM,embedding_weights,MAX_SEQUENCE_LENGTH,len(list(tweet_text['airline_sentiment'].unique())))\n",
        "\n",
        "def scheduler(epoch):\n",
        "  if epoch < 10:\n",
        "    return 0.01\n",
        "  else:\n",
        "    return 0.0001 * tf.math.exp(0.1 * (10 - epoch))\n",
        "lr_scheduler = LearningRateScheduler(scheduler)\n",
        "callback = EarlyStopping(monitor='val_loss', patience=10,restore_best_weights=True,mode=\"min\")\n",
        "# This callback will stop the training when there is no improvement in\n",
        "# the validation loss for 5 consecutive epochs.\n",
        "model.fit(x_train, y_train, epochs=50, callbacks=[callback,lr_scheduler],validation_data=(x_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_32\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_32 (Embedding)     (None, 34, 300)           4004100   \n",
            "_________________________________________________________________\n",
            "bidirectional_9 (Bidirection (None, 200)               320800    \n",
            "_________________________________________________________________\n",
            "dropout_20 (Dropout)         (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_34 (Dense)             (None, 100)               20100     \n",
            "_________________________________________________________________\n",
            "dense_35 (Dense)             (None, 3)                 303       \n",
            "=================================================================\n",
            "Total params: 4,345,303\n",
            "Trainable params: 341,203\n",
            "Non-trainable params: 4,004,100\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/50\n",
            "321/321 [==============================] - 3s 11ms/step - loss: 0.8267 - acc: 0.6640 - val_loss: 0.7453 - val_acc: 0.6926 - lr: 0.0100\n",
            "Epoch 2/50\n",
            "321/321 [==============================] - 3s 9ms/step - loss: 0.6006 - acc: 0.7662 - val_loss: 0.5983 - val_acc: 0.7782 - lr: 0.0100\n",
            "Epoch 3/50\n",
            "321/321 [==============================] - 3s 9ms/step - loss: 0.5415 - acc: 0.7906 - val_loss: 0.6202 - val_acc: 0.8005 - lr: 0.0100\n",
            "Epoch 4/50\n",
            "321/321 [==============================] - 3s 9ms/step - loss: 0.4970 - acc: 0.8137 - val_loss: 0.5444 - val_acc: 0.8233 - lr: 0.0100\n",
            "Epoch 5/50\n",
            "321/321 [==============================] - 3s 9ms/step - loss: 0.4620 - acc: 0.8244 - val_loss: 0.5177 - val_acc: 0.8224 - lr: 0.0100\n",
            "Epoch 6/50\n",
            "321/321 [==============================] - 3s 9ms/step - loss: 0.4261 - acc: 0.8465 - val_loss: 0.5593 - val_acc: 0.8074 - lr: 0.0100\n",
            "Epoch 7/50\n",
            "321/321 [==============================] - 3s 9ms/step - loss: 0.3995 - acc: 0.8491 - val_loss: 0.5898 - val_acc: 0.7996 - lr: 0.0100\n",
            "Epoch 8/50\n",
            "321/321 [==============================] - 3s 9ms/step - loss: 0.3767 - acc: 0.8617 - val_loss: 0.5189 - val_acc: 0.8192 - lr: 0.0100\n",
            "Epoch 9/50\n",
            "321/321 [==============================] - 3s 9ms/step - loss: 0.3509 - acc: 0.8730 - val_loss: 0.6244 - val_acc: 0.8119 - lr: 0.0100\n",
            "Epoch 10/50\n",
            "321/321 [==============================] - 3s 9ms/step - loss: 0.3407 - acc: 0.8776 - val_loss: 0.6189 - val_acc: 0.7773 - lr: 0.0100\n",
            "Epoch 11/50\n",
            "321/321 [==============================] - 3s 9ms/step - loss: 0.2973 - acc: 0.8908 - val_loss: 0.5825 - val_acc: 0.7983 - lr: 1.0000e-04\n",
            "Epoch 12/50\n",
            "321/321 [==============================] - 3s 9ms/step - loss: 0.2762 - acc: 0.8989 - val_loss: 0.5859 - val_acc: 0.8015 - lr: 9.0484e-05\n",
            "Epoch 13/50\n",
            "321/321 [==============================] - 3s 9ms/step - loss: 0.2762 - acc: 0.8972 - val_loss: 0.5915 - val_acc: 0.8037 - lr: 8.1873e-05\n",
            "Epoch 14/50\n",
            "321/321 [==============================] - 3s 9ms/step - loss: 0.2661 - acc: 0.9043 - val_loss: 0.5970 - val_acc: 0.8037 - lr: 7.4082e-05\n",
            "Epoch 15/50\n",
            "321/321 [==============================] - 3s 9ms/step - loss: 0.2612 - acc: 0.9035 - val_loss: 0.5996 - val_acc: 0.8060 - lr: 6.7032e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3f9076b0b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kd7v6qwbS-Xi",
        "colab_type": "code",
        "outputId": "1209d693-6517-4ab9-e4d5-0b9716bb39c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "model.evaluate(x_test, y_test, batch_size = 128)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5010 - acc: 0.7942\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5009780526161194, 0.7941712141036987]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Snz2oGCUN9x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRcxgrF2GNU6",
        "colab_type": "text"
      },
      "source": [
        "Deep LSTM Network "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sI37Tcc8GROh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Deep_LSTM_model(num_words,EMBEDDING_DIM,embedding_weights,max_sequence_length,labels_index):\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(num_words, EMBEDDING_DIM, weights=[embedding_weights],\n",
        "                      input_length=max_sequence_length,\n",
        "                     trainable=False))\n",
        "  model.add(LSTM(100,dropout=0.2,return_sequences=True))\n",
        "  model.add(LSTM(100,dropout=0.2,return_sequences=True))\n",
        "  model.add(LSTM(100,dropout=0.2))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(labels_index, activation='sigmoid'))\n",
        "  print(model.summary())\n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "                optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-3),\n",
        "                metrics=['acc'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zmpi90SGGidi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        },
        "outputId": "fae1d5ee-10a7-4648-e6f5-53bd1cb203f2"
      },
      "source": [
        "model = Deep_LSTM_model(num_words, EMBEDDING_DIM,embedding_weights,MAX_SEQUENCE_LENGTH,len(list(tweet_text['airline_sentiment'].unique())))\n",
        "\n",
        "def scheduler(epoch):\n",
        "  if epoch < 10:\n",
        "    return 0.01\n",
        "  else:\n",
        "    return 0.0001 * tf.math.exp(0.1 * (10 - epoch))\n",
        "lr_scheduler = LearningRateScheduler(scheduler)\n",
        "callback = EarlyStopping(monitor='val_loss', patience=10,restore_best_weights=True,mode=\"min\")\n",
        "# This callback will stop the training when there is no improvement in\n",
        "# the validation loss for 5 consecutive epochs.\n",
        "model.fit(x_train, y_train, epochs=50, callbacks=[callback,lr_scheduler],validation_data=(x_val, y_val))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 34, 300)           4004100   \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 34, 100)           160400    \n",
            "_________________________________________________________________\n",
            "lstm_5 (LSTM)                (None, 34, 100)           80400     \n",
            "_________________________________________________________________\n",
            "lstm_6 (LSTM)                (None, 100)               80400     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 303       \n",
            "=================================================================\n",
            "Total params: 4,325,603\n",
            "Trainable params: 321,503\n",
            "Non-trainable params: 4,004,100\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/50\n",
            "321/321 [==============================] - 5s 14ms/step - loss: 0.8466 - acc: 0.6562 - val_loss: 0.6908 - val_acc: 0.7423 - lr: 0.0100\n",
            "Epoch 2/50\n",
            "321/321 [==============================] - 4s 12ms/step - loss: 0.6555 - acc: 0.7471 - val_loss: 0.6034 - val_acc: 0.7782 - lr: 0.0100\n",
            "Epoch 3/50\n",
            "321/321 [==============================] - 4s 11ms/step - loss: 0.5673 - acc: 0.7834 - val_loss: 0.5319 - val_acc: 0.7996 - lr: 0.0100\n",
            "Epoch 4/50\n",
            "321/321 [==============================] - 4s 11ms/step - loss: 0.5132 - acc: 0.8072 - val_loss: 0.5223 - val_acc: 0.8138 - lr: 0.0100\n",
            "Epoch 5/50\n",
            "321/321 [==============================] - 4s 11ms/step - loss: 0.4725 - acc: 0.8270 - val_loss: 0.5105 - val_acc: 0.8124 - lr: 0.0100\n",
            "Epoch 6/50\n",
            "321/321 [==============================] - 4s 11ms/step - loss: 0.4408 - acc: 0.8396 - val_loss: 0.5253 - val_acc: 0.7969 - lr: 0.0100\n",
            "Epoch 7/50\n",
            "321/321 [==============================] - 4s 11ms/step - loss: 0.4024 - acc: 0.8553 - val_loss: 0.5123 - val_acc: 0.8119 - lr: 0.0100\n",
            "Epoch 8/50\n",
            "321/321 [==============================] - 4s 11ms/step - loss: 0.3868 - acc: 0.8623 - val_loss: 0.5297 - val_acc: 0.8124 - lr: 0.0100\n",
            "Epoch 9/50\n",
            "321/321 [==============================] - 4s 11ms/step - loss: 0.3615 - acc: 0.8713 - val_loss: 0.6515 - val_acc: 0.8110 - lr: 0.0100\n",
            "Epoch 10/50\n",
            "321/321 [==============================] - 4s 11ms/step - loss: 0.3375 - acc: 0.8810 - val_loss: 0.5812 - val_acc: 0.7837 - lr: 0.0100\n",
            "Epoch 11/50\n",
            "321/321 [==============================] - 4s 11ms/step - loss: 0.2863 - acc: 0.9048 - val_loss: 0.6013 - val_acc: 0.8010 - lr: 1.0000e-04\n",
            "Epoch 12/50\n",
            "321/321 [==============================] - 4s 11ms/step - loss: 0.2735 - acc: 0.9055 - val_loss: 0.6215 - val_acc: 0.8060 - lr: 9.0484e-05\n",
            "Epoch 13/50\n",
            "321/321 [==============================] - 4s 11ms/step - loss: 0.2728 - acc: 0.9044 - val_loss: 0.6272 - val_acc: 0.8074 - lr: 8.1873e-05\n",
            "Epoch 14/50\n",
            "321/321 [==============================] - 4s 11ms/step - loss: 0.2573 - acc: 0.9126 - val_loss: 0.6354 - val_acc: 0.8083 - lr: 7.4082e-05\n",
            "Epoch 15/50\n",
            "321/321 [==============================] - 4s 11ms/step - loss: 0.2618 - acc: 0.9083 - val_loss: 0.6383 - val_acc: 0.8078 - lr: 6.7032e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc54026cda0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvHrVu_6HCRG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d8afb515-cd1a-48f8-a530-2234c0834c4b"
      },
      "source": [
        "model.evaluate(x_test, y_test, batch_size = 128)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5292 - acc: 0.8097\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5291927456855774, 0.8096539378166199]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICUgHVcmH6Ho",
        "colab_type": "text"
      },
      "source": [
        "Model weights extraction "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZT-lSoQH8sl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4e75f671-f0e1-4b33-935b-eecea907bef6"
      },
      "source": [
        "for e in zip(model.layers[1].trainable_weights, model.layers[1].get_weights()):\n",
        "  print('Param %s:\\n%s' % (e[0],e[1]))\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Param <tf.Variable 'lstm_4/lstm_cell_4/kernel:0' shape=(300, 400) dtype=float32, numpy=\n",
            "array([[-0.62566406, -0.19284685,  0.06901129, ..., -0.22694892,\n",
            "        -0.9761474 , -0.18277022],\n",
            "       [-0.14448401, -0.20136186, -0.08714977, ..., -0.02943275,\n",
            "         0.22990897, -0.24407145],\n",
            "       [-0.37502635, -0.38083982,  0.7504096 , ..., -0.24946189,\n",
            "        -0.18547767, -0.49076247],\n",
            "       ...,\n",
            "       [ 0.39293703,  0.27259287,  0.08014014, ...,  0.07944054,\n",
            "         0.32485613, -0.23155512],\n",
            "       [-0.3665875 , -0.2076555 , -0.06240206, ..., -0.00664771,\n",
            "        -0.0648846 , -0.01105047],\n",
            "       [ 0.38626614, -0.07425579, -0.2517469 , ...,  0.10659853,\n",
            "        -0.249037  , -0.07017116]], dtype=float32)>:\n",
            "[[-0.62566406 -0.19284685  0.06901129 ... -0.22694892 -0.9761474\n",
            "  -0.18277022]\n",
            " [-0.14448401 -0.20136186 -0.08714977 ... -0.02943275  0.22990897\n",
            "  -0.24407145]\n",
            " [-0.37502635 -0.38083982  0.7504096  ... -0.24946189 -0.18547767\n",
            "  -0.49076247]\n",
            " ...\n",
            " [ 0.39293703  0.27259287  0.08014014 ...  0.07944054  0.32485613\n",
            "  -0.23155512]\n",
            " [-0.3665875  -0.2076555  -0.06240206 ... -0.00664771 -0.0648846\n",
            "  -0.01105047]\n",
            " [ 0.38626614 -0.07425579 -0.2517469  ...  0.10659853 -0.249037\n",
            "  -0.07017116]]\n",
            "Param <tf.Variable 'lstm_4/lstm_cell_4/recurrent_kernel:0' shape=(100, 400) dtype=float32, numpy=\n",
            "array([[-0.10485423,  0.28310722,  0.32318997, ..., -0.01913816,\n",
            "         0.19442892,  0.27579403],\n",
            "       [-0.18827122, -0.14392453, -0.38586667, ..., -0.0848207 ,\n",
            "        -0.88327086,  0.27844784],\n",
            "       [-0.16813049,  0.5482095 , -0.29797742, ...,  0.2339606 ,\n",
            "        -0.38911346, -0.2250997 ],\n",
            "       ...,\n",
            "       [ 1.0037613 ,  0.48383257,  0.11591721, ...,  0.60620314,\n",
            "         0.3362434 ,  0.3306324 ],\n",
            "       [ 0.65432584, -0.1751005 , -0.18604615, ..., -0.5539748 ,\n",
            "         0.7478515 ,  0.11180431],\n",
            "       [ 0.01185398, -0.38878003, -0.29463866, ..., -0.41836306,\n",
            "        -0.01866927, -0.18517804]], dtype=float32)>:\n",
            "[[-0.10485423  0.28310722  0.32318997 ... -0.01913816  0.19442892\n",
            "   0.27579403]\n",
            " [-0.18827122 -0.14392453 -0.38586667 ... -0.0848207  -0.88327086\n",
            "   0.27844784]\n",
            " [-0.16813049  0.5482095  -0.29797742 ...  0.2339606  -0.38911346\n",
            "  -0.2250997 ]\n",
            " ...\n",
            " [ 1.0037613   0.48383257  0.11591721 ...  0.60620314  0.3362434\n",
            "   0.3306324 ]\n",
            " [ 0.65432584 -0.1751005  -0.18604615 ... -0.5539748   0.7478515\n",
            "   0.11180431]\n",
            " [ 0.01185398 -0.38878003 -0.29463866 ... -0.41836306 -0.01866927\n",
            "  -0.18517804]]\n",
            "Param <tf.Variable 'lstm_4/lstm_cell_4/bias:0' shape=(400,) dtype=float32, numpy=\n",
            "array([ 1.41491100e-01, -5.93743861e-01,  1.05793208e-01, -6.28835559e-01,\n",
            "       -7.64879644e-01, -3.80369872e-02, -4.53723758e-01, -5.63772857e-01,\n",
            "       -1.32035166e-01, -5.98602772e-01, -3.35857898e-01, -5.63947439e-01,\n",
            "       -6.01476669e-01, -9.45557892e-01, -8.86488676e-01, -6.58926010e-01,\n",
            "       -2.30947450e-01, -4.06674981e-01, -9.75669920e-01, -5.73657751e-01,\n",
            "       -2.66647786e-01,  2.16572344e-01, -5.99107563e-01, -1.21079600e+00,\n",
            "       -4.16118383e-01, -6.55039489e-01, -4.89679098e-01, -9.30257067e-02,\n",
            "       -3.45879346e-01, -4.40272510e-01, -2.00037837e-01, -2.60747910e-01,\n",
            "       -3.55347365e-01, -9.12248611e-01, -1.07347405e+00, -7.05996037e-01,\n",
            "       -5.10256648e-01, -4.11211252e-01, -5.07126033e-01, -4.23945725e-01,\n",
            "       -4.63860571e-01, -6.92237020e-01, -4.55781251e-01, -3.56385291e-01,\n",
            "       -7.92216659e-01, -3.69863003e-01, -4.27976727e-01, -9.52497005e-01,\n",
            "       -4.76464599e-01,  5.83663762e-01, -2.64920592e-01, -6.50132477e-01,\n",
            "       -3.77462149e-01, -2.19169393e-01, -1.18300855e-01, -7.72141218e-01,\n",
            "       -6.07827604e-02, -3.23176414e-01, -4.78904724e-01, -5.61000586e-01,\n",
            "       -5.52005589e-01, -3.69771600e-01, -2.61650264e-01, -3.29332113e-01,\n",
            "       -5.69340289e-01, -6.49564266e-01, -6.50274336e-01,  1.99517254e-02,\n",
            "       -3.11933756e-01, -8.22008073e-01, -5.63533783e-01, -9.33662832e-01,\n",
            "       -5.94826162e-01, -1.99114993e-01, -1.36583149e-01, -9.11655873e-02,\n",
            "       -2.49162853e-01, -6.75734937e-01, -8.69785070e-01, -3.88832539e-01,\n",
            "       -3.99246871e-01, -5.09871766e-02, -3.85961771e-01, -6.19174838e-01,\n",
            "       -5.29811561e-01, -3.55336756e-01, -5.70548654e-01, -5.15725255e-01,\n",
            "       -7.56484121e-02, -2.37582460e-01,  4.11983430e-02, -3.68346602e-01,\n",
            "       -8.08919728e-01, -4.68198687e-01, -7.38369346e-01, -5.14061868e-01,\n",
            "       -4.25137490e-01, -2.03004777e-02, -7.43727207e-01,  1.26873165e-01,\n",
            "        8.27845514e-01,  5.50733805e-02,  8.30533266e-01,  7.67044425e-01,\n",
            "        7.68593729e-01,  7.55894303e-01,  8.86394024e-01,  2.40048349e-01,\n",
            "        1.08716317e-01,  1.09907866e+00,  9.01283622e-01,  6.42439961e-01,\n",
            "        4.49891299e-01,  8.60613585e-01,  3.05296987e-01,  5.27614117e-01,\n",
            "        8.63049328e-01,  8.02983522e-01, -4.41773236e-02,  2.99453378e-01,\n",
            "        1.17919052e+00,  1.13227773e+00,  1.81673393e-01,  8.26684356e-01,\n",
            "        8.68704617e-01,  5.57691813e-01,  6.18946910e-01,  3.53652179e-01,\n",
            "        5.85767329e-01,  1.10603321e+00,  4.48098809e-01,  9.22203183e-01,\n",
            "        5.64483941e-01,  7.19460905e-01,  9.71874475e-01,  1.13589513e+00,\n",
            "        1.24814320e+00,  6.19952917e-01,  1.74674496e-01,  6.35272324e-01,\n",
            "        5.22866726e-01,  8.31229329e-01,  6.13890231e-01,  7.12383330e-01,\n",
            "        8.28748405e-01,  5.96440911e-01,  4.69015986e-01,  2.11357877e-01,\n",
            "        5.36341846e-01,  8.06491315e-01,  3.46834928e-01,  1.49239600e-01,\n",
            "        9.94632691e-02,  1.22494459e-01,  7.90601730e-01,  1.04438257e+00,\n",
            "        1.00334418e+00,  8.62339318e-01,  3.43841493e-01,  4.34296787e-01,\n",
            "        7.05506563e-01,  7.66080737e-01,  8.54237974e-01,  7.65086651e-01,\n",
            "        5.85237026e-01,  8.04337800e-01,  6.05352998e-01,  6.74575210e-01,\n",
            "        4.52006161e-01, -1.61550194e-01,  1.21381986e+00,  3.94257069e-01,\n",
            "        7.71845162e-01,  5.32814562e-01,  6.05809689e-01,  1.16180170e+00,\n",
            "        5.47798693e-01,  8.90441835e-01,  7.32733250e-01,  8.80191863e-01,\n",
            "        7.82074571e-01,  8.94454539e-01,  8.86258543e-01,  7.96888649e-01,\n",
            "        8.56522977e-01,  1.32841676e-01,  3.28680336e-01,  6.40902281e-01,\n",
            "        8.89183104e-01,  4.47701037e-01,  7.02132165e-01,  7.88579881e-01,\n",
            "        9.64626223e-02,  7.59918272e-01,  9.35198307e-01,  7.87783265e-01,\n",
            "        4.39787090e-01,  6.02133334e-01,  2.00687826e-01,  8.10635328e-01,\n",
            "       -2.16006026e-01, -2.39529565e-01, -5.90813230e-04,  1.51369750e-01,\n",
            "       -9.30659249e-02, -4.17014748e-01, -3.71304452e-02, -2.51283739e-02,\n",
            "       -3.96664888e-01,  2.25283802e-01,  2.07257092e-01, -2.23322734e-02,\n",
            "        2.00074121e-01, -1.55152336e-01,  2.60627449e-01,  2.32217461e-02,\n",
            "        3.46893370e-01,  1.93775803e-01, -1.26153886e-01,  6.38430044e-02,\n",
            "       -1.93699881e-01, -5.49303472e-01, -1.52367160e-01,  2.38827541e-01,\n",
            "        1.80108204e-01,  1.38550252e-01, -2.57310063e-01,  6.68248311e-02,\n",
            "        2.57687360e-01, -3.36197913e-02, -6.55137841e-03,  2.72765338e-01,\n",
            "        2.51778625e-02, -3.04536760e-01,  2.80556470e-01,  3.00007105e-01,\n",
            "       -1.97102837e-02,  1.28331989e-01,  4.54381198e-01, -3.98863763e-01,\n",
            "       -9.42465886e-02,  2.04283014e-01,  5.70272148e-01,  1.17907003e-01,\n",
            "       -1.10264637e-01,  2.47574435e-03,  2.38343813e-02, -4.32186164e-02,\n",
            "        5.18199623e-01, -3.50530326e-01,  1.34757370e-01,  1.48947164e-01,\n",
            "        8.45291764e-02, -1.88349903e-01, -2.39101082e-01,  2.11415917e-01,\n",
            "       -3.39019418e-01,  6.80852532e-02,  8.50429833e-02,  1.46601021e-01,\n",
            "       -9.24527459e-03, -8.93621072e-02,  4.16393764e-02, -3.60725857e-02,\n",
            "       -1.80380434e-01,  1.92461923e-01,  2.80197591e-01,  3.38969797e-01,\n",
            "        1.81128219e-01,  2.82786250e-01,  1.11110032e-01, -4.09863651e-01,\n",
            "       -6.18617646e-02,  2.65797824e-01, -3.34273010e-01,  2.46645659e-01,\n",
            "        2.02940270e-01,  2.66122103e-01, -3.38190854e-01, -2.29867846e-01,\n",
            "        2.87541151e-01, -1.99125960e-01,  1.15815252e-01,  1.19189806e-01,\n",
            "       -1.57373473e-01,  3.48696932e-02,  1.87091187e-01, -3.51952851e-01,\n",
            "        2.80255973e-01,  7.08524585e-02,  1.14754066e-01,  9.40899253e-02,\n",
            "        6.10969700e-02, -1.98481679e-01, -2.20649287e-01,  2.16604561e-01,\n",
            "        2.39394754e-01,  1.27417892e-01,  5.31071872e-02,  7.99923167e-02,\n",
            "        2.14148276e-02, -7.10896611e-01, -1.68642759e-01, -3.81528407e-01,\n",
            "       -2.30366752e-01, -8.17022324e-01,  1.11195393e-01, -5.63090444e-01,\n",
            "       -1.44405603e-01, -4.12146032e-01, -5.71364880e-01, -4.96153682e-01,\n",
            "       -7.86212802e-01,  1.31217733e-01, -7.52034187e-01, -2.21998289e-01,\n",
            "       -6.16207480e-01, -3.12373549e-01, -9.21152592e-01, -1.08713496e+00,\n",
            "       -4.46800351e-01,  5.15337475e-03, -6.65878177e-01, -8.62943679e-02,\n",
            "       -2.63454765e-01, -7.01889098e-01, -2.74433196e-01, -3.62240851e-01,\n",
            "       -4.24673483e-02, -5.72709024e-01, -5.45915246e-01, -1.52173802e-01,\n",
            "       -2.05128476e-01, -5.18951416e-01,  2.87175208e-01, -3.08397204e-01,\n",
            "       -6.26909673e-01, -5.45822024e-01, -7.03393638e-01, -5.30401111e-01,\n",
            "       -6.27203941e-01, -4.92172927e-01, -2.12872133e-01, -2.82211125e-01,\n",
            "       -5.69354296e-01, -2.59849280e-01, -7.97302723e-01, -9.55311954e-01,\n",
            "       -5.37685156e-01, -3.96017224e-01, -1.42679602e-01, -2.55271405e-01,\n",
            "       -4.59744900e-01, -2.49847680e-01, -2.50902027e-02, -7.19312072e-01,\n",
            "       -4.78055000e-01, -4.74667847e-01, -5.52471817e-01, -5.47101378e-01,\n",
            "       -7.84400046e-01, -1.70341909e-01, -5.45036316e-01, -2.93495525e-02,\n",
            "       -3.76331747e-01, -6.09706044e-01, -2.35712498e-01,  2.27292746e-01,\n",
            "       -4.75053549e-01, -9.15439665e-01,  1.15782037e-01, -8.71591032e-01,\n",
            "       -4.97475088e-01, -7.95946121e-02, -3.76728982e-01, -4.05636132e-01,\n",
            "       -1.20599441e-01, -3.85825306e-01,  1.27197981e-01, -2.19594359e-01,\n",
            "        5.54180108e-02, -3.54464591e-01, -2.14704558e-01, -2.69272208e-01,\n",
            "       -2.00451851e-01, -2.71602392e-01, -4.32530016e-01, -3.97599488e-01,\n",
            "        1.26738340e-01, -1.78551897e-01, -1.32216085e-02,  7.46996403e-02,\n",
            "       -6.56318784e-01, -4.26202893e-01, -1.46794647e-01, -2.72739857e-01,\n",
            "       -2.51330584e-01, -4.52551901e-01, -6.02550030e-01, -3.53803068e-01],\n",
            "      dtype=float32)>:\n",
            "[ 1.41491100e-01 -5.93743861e-01  1.05793208e-01 -6.28835559e-01\n",
            " -7.64879644e-01 -3.80369872e-02 -4.53723758e-01 -5.63772857e-01\n",
            " -1.32035166e-01 -5.98602772e-01 -3.35857898e-01 -5.63947439e-01\n",
            " -6.01476669e-01 -9.45557892e-01 -8.86488676e-01 -6.58926010e-01\n",
            " -2.30947450e-01 -4.06674981e-01 -9.75669920e-01 -5.73657751e-01\n",
            " -2.66647786e-01  2.16572344e-01 -5.99107563e-01 -1.21079600e+00\n",
            " -4.16118383e-01 -6.55039489e-01 -4.89679098e-01 -9.30257067e-02\n",
            " -3.45879346e-01 -4.40272510e-01 -2.00037837e-01 -2.60747910e-01\n",
            " -3.55347365e-01 -9.12248611e-01 -1.07347405e+00 -7.05996037e-01\n",
            " -5.10256648e-01 -4.11211252e-01 -5.07126033e-01 -4.23945725e-01\n",
            " -4.63860571e-01 -6.92237020e-01 -4.55781251e-01 -3.56385291e-01\n",
            " -7.92216659e-01 -3.69863003e-01 -4.27976727e-01 -9.52497005e-01\n",
            " -4.76464599e-01  5.83663762e-01 -2.64920592e-01 -6.50132477e-01\n",
            " -3.77462149e-01 -2.19169393e-01 -1.18300855e-01 -7.72141218e-01\n",
            " -6.07827604e-02 -3.23176414e-01 -4.78904724e-01 -5.61000586e-01\n",
            " -5.52005589e-01 -3.69771600e-01 -2.61650264e-01 -3.29332113e-01\n",
            " -5.69340289e-01 -6.49564266e-01 -6.50274336e-01  1.99517254e-02\n",
            " -3.11933756e-01 -8.22008073e-01 -5.63533783e-01 -9.33662832e-01\n",
            " -5.94826162e-01 -1.99114993e-01 -1.36583149e-01 -9.11655873e-02\n",
            " -2.49162853e-01 -6.75734937e-01 -8.69785070e-01 -3.88832539e-01\n",
            " -3.99246871e-01 -5.09871766e-02 -3.85961771e-01 -6.19174838e-01\n",
            " -5.29811561e-01 -3.55336756e-01 -5.70548654e-01 -5.15725255e-01\n",
            " -7.56484121e-02 -2.37582460e-01  4.11983430e-02 -3.68346602e-01\n",
            " -8.08919728e-01 -4.68198687e-01 -7.38369346e-01 -5.14061868e-01\n",
            " -4.25137490e-01 -2.03004777e-02 -7.43727207e-01  1.26873165e-01\n",
            "  8.27845514e-01  5.50733805e-02  8.30533266e-01  7.67044425e-01\n",
            "  7.68593729e-01  7.55894303e-01  8.86394024e-01  2.40048349e-01\n",
            "  1.08716317e-01  1.09907866e+00  9.01283622e-01  6.42439961e-01\n",
            "  4.49891299e-01  8.60613585e-01  3.05296987e-01  5.27614117e-01\n",
            "  8.63049328e-01  8.02983522e-01 -4.41773236e-02  2.99453378e-01\n",
            "  1.17919052e+00  1.13227773e+00  1.81673393e-01  8.26684356e-01\n",
            "  8.68704617e-01  5.57691813e-01  6.18946910e-01  3.53652179e-01\n",
            "  5.85767329e-01  1.10603321e+00  4.48098809e-01  9.22203183e-01\n",
            "  5.64483941e-01  7.19460905e-01  9.71874475e-01  1.13589513e+00\n",
            "  1.24814320e+00  6.19952917e-01  1.74674496e-01  6.35272324e-01\n",
            "  5.22866726e-01  8.31229329e-01  6.13890231e-01  7.12383330e-01\n",
            "  8.28748405e-01  5.96440911e-01  4.69015986e-01  2.11357877e-01\n",
            "  5.36341846e-01  8.06491315e-01  3.46834928e-01  1.49239600e-01\n",
            "  9.94632691e-02  1.22494459e-01  7.90601730e-01  1.04438257e+00\n",
            "  1.00334418e+00  8.62339318e-01  3.43841493e-01  4.34296787e-01\n",
            "  7.05506563e-01  7.66080737e-01  8.54237974e-01  7.65086651e-01\n",
            "  5.85237026e-01  8.04337800e-01  6.05352998e-01  6.74575210e-01\n",
            "  4.52006161e-01 -1.61550194e-01  1.21381986e+00  3.94257069e-01\n",
            "  7.71845162e-01  5.32814562e-01  6.05809689e-01  1.16180170e+00\n",
            "  5.47798693e-01  8.90441835e-01  7.32733250e-01  8.80191863e-01\n",
            "  7.82074571e-01  8.94454539e-01  8.86258543e-01  7.96888649e-01\n",
            "  8.56522977e-01  1.32841676e-01  3.28680336e-01  6.40902281e-01\n",
            "  8.89183104e-01  4.47701037e-01  7.02132165e-01  7.88579881e-01\n",
            "  9.64626223e-02  7.59918272e-01  9.35198307e-01  7.87783265e-01\n",
            "  4.39787090e-01  6.02133334e-01  2.00687826e-01  8.10635328e-01\n",
            " -2.16006026e-01 -2.39529565e-01 -5.90813230e-04  1.51369750e-01\n",
            " -9.30659249e-02 -4.17014748e-01 -3.71304452e-02 -2.51283739e-02\n",
            " -3.96664888e-01  2.25283802e-01  2.07257092e-01 -2.23322734e-02\n",
            "  2.00074121e-01 -1.55152336e-01  2.60627449e-01  2.32217461e-02\n",
            "  3.46893370e-01  1.93775803e-01 -1.26153886e-01  6.38430044e-02\n",
            " -1.93699881e-01 -5.49303472e-01 -1.52367160e-01  2.38827541e-01\n",
            "  1.80108204e-01  1.38550252e-01 -2.57310063e-01  6.68248311e-02\n",
            "  2.57687360e-01 -3.36197913e-02 -6.55137841e-03  2.72765338e-01\n",
            "  2.51778625e-02 -3.04536760e-01  2.80556470e-01  3.00007105e-01\n",
            " -1.97102837e-02  1.28331989e-01  4.54381198e-01 -3.98863763e-01\n",
            " -9.42465886e-02  2.04283014e-01  5.70272148e-01  1.17907003e-01\n",
            " -1.10264637e-01  2.47574435e-03  2.38343813e-02 -4.32186164e-02\n",
            "  5.18199623e-01 -3.50530326e-01  1.34757370e-01  1.48947164e-01\n",
            "  8.45291764e-02 -1.88349903e-01 -2.39101082e-01  2.11415917e-01\n",
            " -3.39019418e-01  6.80852532e-02  8.50429833e-02  1.46601021e-01\n",
            " -9.24527459e-03 -8.93621072e-02  4.16393764e-02 -3.60725857e-02\n",
            " -1.80380434e-01  1.92461923e-01  2.80197591e-01  3.38969797e-01\n",
            "  1.81128219e-01  2.82786250e-01  1.11110032e-01 -4.09863651e-01\n",
            " -6.18617646e-02  2.65797824e-01 -3.34273010e-01  2.46645659e-01\n",
            "  2.02940270e-01  2.66122103e-01 -3.38190854e-01 -2.29867846e-01\n",
            "  2.87541151e-01 -1.99125960e-01  1.15815252e-01  1.19189806e-01\n",
            " -1.57373473e-01  3.48696932e-02  1.87091187e-01 -3.51952851e-01\n",
            "  2.80255973e-01  7.08524585e-02  1.14754066e-01  9.40899253e-02\n",
            "  6.10969700e-02 -1.98481679e-01 -2.20649287e-01  2.16604561e-01\n",
            "  2.39394754e-01  1.27417892e-01  5.31071872e-02  7.99923167e-02\n",
            "  2.14148276e-02 -7.10896611e-01 -1.68642759e-01 -3.81528407e-01\n",
            " -2.30366752e-01 -8.17022324e-01  1.11195393e-01 -5.63090444e-01\n",
            " -1.44405603e-01 -4.12146032e-01 -5.71364880e-01 -4.96153682e-01\n",
            " -7.86212802e-01  1.31217733e-01 -7.52034187e-01 -2.21998289e-01\n",
            " -6.16207480e-01 -3.12373549e-01 -9.21152592e-01 -1.08713496e+00\n",
            " -4.46800351e-01  5.15337475e-03 -6.65878177e-01 -8.62943679e-02\n",
            " -2.63454765e-01 -7.01889098e-01 -2.74433196e-01 -3.62240851e-01\n",
            " -4.24673483e-02 -5.72709024e-01 -5.45915246e-01 -1.52173802e-01\n",
            " -2.05128476e-01 -5.18951416e-01  2.87175208e-01 -3.08397204e-01\n",
            " -6.26909673e-01 -5.45822024e-01 -7.03393638e-01 -5.30401111e-01\n",
            " -6.27203941e-01 -4.92172927e-01 -2.12872133e-01 -2.82211125e-01\n",
            " -5.69354296e-01 -2.59849280e-01 -7.97302723e-01 -9.55311954e-01\n",
            " -5.37685156e-01 -3.96017224e-01 -1.42679602e-01 -2.55271405e-01\n",
            " -4.59744900e-01 -2.49847680e-01 -2.50902027e-02 -7.19312072e-01\n",
            " -4.78055000e-01 -4.74667847e-01 -5.52471817e-01 -5.47101378e-01\n",
            " -7.84400046e-01 -1.70341909e-01 -5.45036316e-01 -2.93495525e-02\n",
            " -3.76331747e-01 -6.09706044e-01 -2.35712498e-01  2.27292746e-01\n",
            " -4.75053549e-01 -9.15439665e-01  1.15782037e-01 -8.71591032e-01\n",
            " -4.97475088e-01 -7.95946121e-02 -3.76728982e-01 -4.05636132e-01\n",
            " -1.20599441e-01 -3.85825306e-01  1.27197981e-01 -2.19594359e-01\n",
            "  5.54180108e-02 -3.54464591e-01 -2.14704558e-01 -2.69272208e-01\n",
            " -2.00451851e-01 -2.71602392e-01 -4.32530016e-01 -3.97599488e-01\n",
            "  1.26738340e-01 -1.78551897e-01 -1.32216085e-02  7.46996403e-02\n",
            " -6.56318784e-01 -4.26202893e-01 -1.46794647e-01 -2.72739857e-01\n",
            " -2.51330584e-01 -4.52551901e-01 -6.02550030e-01 -3.53803068e-01]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gI6fALb9IG0q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "a96c0efe-1775-4d8a-b1a7-0bf68bd331e7"
      },
      "source": [
        "units = 100\n",
        "layers = [1,2,3]\n",
        "for i in layers:\n",
        "  W = model.layers[i].get_weights()[0]\n",
        "  U = model.layers[i].get_weights()[1]\n",
        "  b = model.layers[i].get_weights()[2]\n",
        "\n",
        "  W_i = W[:, :units]\n",
        "  W_f = W[:, units: units * 2]\n",
        "  W_c = W[:, units * 2: units * 3]\n",
        "  W_o = W[:, units * 3:]\n",
        "\n",
        "  U_i = U[:, :units]\n",
        "  U_f = U[:, units: units * 2]\n",
        "  U_c = U[:, units * 2: units * 3]\n",
        "  U_o = U[:, units * 3:]\n",
        "\n",
        "  b_i = b[:units]\n",
        "  b_f = b[units: units * 2]\n",
        "  b_c = b[units * 2: units * 3]\n",
        "  b_o = b[units * 3:]\n",
        "  print(\"\\nlstm layer \" + str(i) + \" shapes\")\n",
        "  print (W.shape, U.shape, b.shape)\n",
        "  print (W_i.shape, W_f.shape, W_c.shape, W_o.shape)\n",
        "  print (U_i.shape,U_f.shape,U_c.shape,U_o.shape)\n",
        "  print (b_i.shape,b_f.shape,b_c.shape,b_o.shape)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "lstm layer 1 shapes\n",
            "(300, 400) (100, 400) (400,)\n",
            "(300, 100) (300, 100) (300, 100) (300, 100)\n",
            "(100, 100) (100, 100) (100, 100) (100, 100)\n",
            "(100,) (100,) (100,) (100,)\n",
            "\n",
            "lstm layer 2 shapes\n",
            "(100, 400) (100, 400) (400,)\n",
            "(100, 100) (100, 100) (100, 100) (100, 100)\n",
            "(100, 100) (100, 100) (100, 100) (100, 100)\n",
            "(100,) (100,) (100,) (100,)\n",
            "\n",
            "lstm layer 3 shapes\n",
            "(100, 400) (100, 400) (400,)\n",
            "(100, 100) (100, 100) (100, 100) (100, 100)\n",
            "(100, 100) (100, 100) (100, 100) (100, 100)\n",
            "(100,) (100,) (100,) (100,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCp-mMVfISvf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}